# Sztywne_Gity_Summary

2.Phonology - Internal Representations and Rules of Sounds

The human brain processes sounds and categorizes them into distinct units based on the language we speak. However, different languages categorize sounds differently, which can lead to misunderstandings when encountering unfamiliar sounds in a new language. This can be illustrated with an analogy of two groups of people, one from the Land of Men with a limited color palette, and another from the Land of Women with a wide range of colors. When the men visit the Land of Women, they struggle to distinguish between different shades of brown used for road signs, leading to confusion and misinterpretation. Similarly, speakers of different languages categorize sounds differently, affecting the way words are perceived and understood. For example, in English, the sounds in 'toe' and 'so' are distinguished by their initial consonants, but in Tok Pisin, these sounds can be interchanged without changing the word's meaning. Understanding how languages classify sounds, known as phonology, is crucial for effective communication. Phonologists study how languages divide the acoustic space into meaningful sound units.

**Phonemes**: Phonemes are the basic units of study in phonology. They are sets of sounds that function as a single unit in a language and distinguish between different words. Speakers categorize certain sounds into phonemes. For example, in Tok Pisin, both [s] and [t] belong to the phoneme /t/.

Aspiration, which is the puff of air accompanying the sound, can vary between words. For instance, if you carefully pronounce the English words "keys" and "schools," you'll notice that the [k] sound in "keys" has aspiration, while it is absent in "schools." However, since aspiration does not change the meaning of a word, both sounds belong to the phoneme /k/. Therefore, the phonetic representations of these words are /kiz/ and /skulz/.

Referring to phonemes is appropriate because they represent an abstraction level away from individual sounds (phones). By focusing on phonemes, we remove certain details that may be interesting but do not significantly impact various aspects of a language.

**Allophony**: Allophones are different pronunciations or variations of the same phoneme. When two phones belong to the same phoneme, they are considered allophones. For example, in Tok Pisin, [t] and [s] are allophones of the phoneme /t/, and in English, [k] and [kʰ] are allophones of the phoneme /k/.

Allophones are often influenced by their surrounding environment, which means that the choice of allophone depends on the context. For instance, in many varieties of American English, the phoneme /t/ is realized as a tap [ɾ] between vowels in normal speech, as in the word "butter." In this case, the plosive [t] and the tap [ɾ] are allophones of the phoneme /t/ and are said to be in complementary distribution. Each environment selects one specific allophone, and they complement each other. Similarly, [k] and [kʰ] in English are in complementary distribution, with [k] occurring mainly in the sequence /sk/ and [kʰ] appearing elsewhere.

On the other hand, allophones can also co-occur in the same environment, indicating free variation. For example, in English, the word-final /t/ phoneme in "cat" can be pronounced with an audible release ([t]) or with the tongue held in the gesture without being released ([t̚]). These phones, represented as [t] and [t̚] in the IPA, are free variants because either pronunciation is allowed in the same position. Similarly, some speakers of Tok Pisin may use both [s] and [t] as free variants of a phoneme.

Allophones and their distribution provide insights into the phonological patterns and rules within a language.

**Minimal pairs**: One way to determine phonemes is through the use of minimal pairs, which are pairs of words that differ by only one sound. For example, in English, words like "do" and "too," "you" and "moo" form minimal pairs. By comparing such pairs, we can establish that the sounds in question represent distinct phonemes because they create differences in meaning and are not simply variations of the same sound (allophones). Minimal pairs demonstrate contrastive distribution, as the segments being compared occur in the same environment and cannot be allophones of each other.

However, relying solely on minimal pairs is not always foolproof, as it may be challenging to find them for certain phonemes even when there is a clear contrast. In some cases, near-minimal pairs can be found, where the words are very similar, making it unlikely that any environmental factors influence allophony.

Determining allophones also requires using common sense and considering the overall intelligibility of the language. Some phonemes may exhibit complementary distribution without being likely allophones. For instance, in English, the phonemes /h/ and /ŋ/ occur in the word "hung," but they cannot appear in the same environment since /h/ is always syllable-initial and /ŋ/ is always syllable-final. Despite their complementary distribution, they are considered distinct phonemes because they are audibly different, substituting one for the other would result in unintelligibility, and English speakers do not confuse them.

It's important to note that there is no universally agreed-upon method to determine allophones definitively, and debates exist in many languages regarding the classification of sounds.

Phonological Rules

**Phonotactics**: Phonotactics refer to the rules that dictate how phonemes can be organized within a language. These rules determine the permissible arrangements of sounds. In English, for example, certain combinations like 'pf' and 'dchb' are not allowed at the beginning of syllables, while 'bg' is not allowed at the end. This is why words like "Pfilg," "Dchbin," and "Riaubg" are considered unpronounceable. On the other hand, words like "Mard" and "Droib" adhere to English phonotactics and have a more familiar feel.

An example of creative use of words that follow phonotactics is found in Lewis Carroll's poem "Jabberwocky", where he invents nonsensical words that still adhere to the phonotactic rules of English.
Couple of stanzas from his famed work:

>'Twas brillig, and the slithy toves
>
>Did gyre and gimble in the wabe;
>
>All mimsy were the borogoves,
>
>And the mome raths outgrabe.'
>
>"Beware the Jabberwock, my son!
>
>The jaws that bite, the claws that catch!
>
>Beware the Jubjub bird, and shun
>
>The frumious Bandersnatch!"

Different languages have their own distinct phonotactics. For instance, the Czech Republic has cities named Brno and Plzeň, which demonstrate the allowance for complex consonant clusters in Czech. In Mandarin, however, phonotactics are different, and they do not permit complex consonant clusters. As a result, the Mandarin equivalent of Amsterdam is "Amusitedan."

Understanding phonotactics helps us analyze the organization of sounds within a language and explains why certain word formations feel natural or unfamiliar in different languages.

**Morphophonology**, also known as morphophonemics, examines the interaction between the structure of words (morphology) and their pronunciation (phonology). It involves analyzing the underlying or morpho-phonemic representations of words, which are abstract representations below the phonemic level. An example of this can be seen in Biloxi words, where different forms of words exhibit phonological changes:

- "de" (he goes) becomes "da" (don't go)
- "ande" (he is) becomes "anda" (be!)
- "ide" (it falls) becomes "ide" (fall!)
- "da" (he gathers) remains "da" (gather!)

Morphophonology is also used to address cases of neutralization and underspecification. For instance, in Turkish, certain words show patterns where final stops are always devoiced, but some stops voice when followed by a vowel added through suffixing, while others remain voiceless. Although both "et" (meat) and "eti" (his meat) are represented phonemically as /et/ to maintain contrast, it is acknowledged that the word for "to do" underlyingly ends in a different segment, which doesn't surface in certain positions. This underlying or morpho-phonemic representation is denoted with pipes (||), such as |et|, |eti|, |ed|, and |edi|.

The parallelism between the morpho-phonemic layer and the phonemic layer is evident. Just as phonemes are realized as specific sounds based on their environment, underlying segments in morpho-phonology are realized as phonemes. The key distinction is that the surfacing of morpho-phonemic segments as phonemes occurs after morphological processes (e.g., adding word endings) have taken place. Morphophonology is informed by morphology, whereas plain phonology is not.

**Issue**:
In certain linguistic frameworks, such as phonetics and phonology, it is useful to categorize a language's sounds into distinct types called phonemes. Phonemes are considered abstract entities that represent sound categories and transcend the specific phonetic realizations and variations of a sound in a language.

For instance, the English phoneme /l/ is posited to exist because it creates a noticeable contrast with similar-sounding words like 'right' or 'write,' which have the distinct phoneme /r/ instead of /l/ at the beginning. This contrast between 'light' and 'write' illustrates that, at least in English, the phonemes /l/ and /r/ are distinct sound categories.

However, this phonemic model has a fundamental weakness in terms of circular logic. Phonemes are used to define the semantic aspects of language (lexical or higher-level meaning), but the phonological realm is then defined based on semantic means, such as minimal pairs of words like 'light' vs. 'right' or 'pay' vs. 'bay.' Additionally, if phonemes and minimal pairs were such precise tools, they would not result in such wide variations in sound inventories across languages (e.g., English with 38–50 phonemes). Furthermore, most words differentiate meaning based on more information than just a contrast between two sounds.

The phoneme is primarily a construct of structuralist and/or psycholinguistic categories within phonology. It is ideally supposed to exist across variations known as allophones and can be realized differently, such as the so-called 'clear' [l] at the beginning of a word like 'like' or the so-called 'dark' [l] at the end of a word like 'feel.'

These concerns primarily fall outside the domain of phonetics because structuralist and/or psycholinguistic categories pertain to cognitive and mental aspects of language processing and acquisition. In other words, the phoneme may or may not be a reality in phonology, but it is not a physical component of realized speech in the vocal tract. Actual speech is co-articulated, involves movement, and spreads sound aspects over entire syllables and words. While it is convenient to consider speech as a sequence of segments (which may or may not closely align with ideal phonemic segments) for discussion in written form, phonetic analysis of speech contradicts such a model.

However, it should be noted that if we aim to represent dynamic and complex speech using static writing, constructs like phonemes serve as convenient fictions to convey what we are attempting to transcribe (alternative units for capturing language in written form include the syllable and the word).

4.Syntax

Syntax is one of the fields of linguistics which studies the well-formedness of phrases and sentences. Syntacticians investigate the grammar of a chosen language or generative grammar, which proposes that there is a universal grammar shared by all languages. This theory aims to examine grammatical rules and their cross-linguistic variations. Generative grammar has gained worldwide recognition among syntacticians. However, there are competing theories, such as construction grammar and cognitive linguistics, which either reject or remain neutral on the idea of the universal grammar.

In syntax, it is crucial to understand the distinction between grammaticality and semantic soundness.Grammaticality refers to the adherence to syntactic rules in constructing sentences, whereas semantic soundness relates to the meaningfulness or coherence of a sentence. Hence, a sentence may be grammatical even if it is semantically nonsensical. For instance, the following sentence: "Colorless green ideas sleep furiously.", coined by Noam Chomsky, is well-formed but does not make any sense.
The basic units of syntax are words and clitics. Words are independent units with semantic and pragmatic content, while clitics are syntactically similar to words but rely on another element phonologically. Both words and clitics can be categorised into classes, known as lexical categories. Their classification is based on their distribution within a sentence, the affixes they can take, and the type of meaning they express. A list of these categories includes: noun(N), proper noun(PN), pronoun(PR), verb(V), adjective(A), adposition(AP), adverb(Adv), degree word(Deg), auxiliary(Aux), modal auxiliary(Mod), interjection(I), determiner(D or Det), conjunction(Con), coordinate conjunction(Co) and subordinate conjunction(Sub).


In syntax, it is crucial to understand the distinction between grammaticality and semantic soundness.Grammaticality refers to the adherence to syntactic rules in constructing sentences, whereas semantic soundness relates to the meaningfulness or coherence of a sentence. Hence, a sentence may be grammatical even if it is semantically nonsensical. For instance, the following sentence: "Colorless green ideas sleep furiously.", coined by Noam Chomsky, is well-formed but does not make any sense. 

The basic units of syntax are words and clitics. Words are independent units with semantic and pragmatic content, while clitics are syntactically similar to words but rely on another element phonologically. Both words and clitics can be categorised into classes, known as lexical categories. Their classification is based on their distribution within a sentence, the affixes they can take, and the type of meaning they express. A list of these categories includes: noun(N), proper noun(PN), pronoun(PR), verb(V), adjective(A), adposition(AP), adverb(Adv), degree word(Deg), auxiliary(Aux), modal auxiliary(Mod), interjection(I), determiner(D or Det), conjunction(Con), coordinate conjunction(Co) and subordinate conjunction(Sub).


Each lexical category has a corresponding constituent or phrasal category, referred to as syntactic categories. Constituents are assigned to these categories using similar criteria as those used for assigning words and clitics to lexical categories. In the sentence "I see _____", only the constituents of the same category as "the big man" can fill the gap. Certain phrases, such as "doll" or "happy camper", do not fit. The structure that fits into the blank is called a noun phrase (NP). The analysis presented here is called structural analysis. It involves determining the type of constituent that can be placed in a specific part of the sentence. Nevertheless, this approach may not allow us to see the overall structure of the sentence and understand its meaning fully.

In constituent analysis, sentences were viewed as blocks of constituents that can be combined in different ways. However, this analysis fails to capture a hierarchical structure in the sentence. The phrase "hit the big man" makes sense as it describes a real action, whereas "I hit" does not make sense because "hit" requires an object. This suggests that "I" and "hit the big man" are larger constituents, traditionally known as the subject and predicate. The following sentence can be separated into constituents as follows: [I [hit [the big man]]].

Syntax trees are introduced as a schematic way to represent the structure of sentences. Constituents are known as nodes, which are connected by branches. Phrases typically consist of two constituents, adhering to the binary branching condition. The head of a phrase determines the syntactic category of the phrase. In other words, in the verb phrase: [hit [the big man]], hit is the head of the verb phrase.

![Tree](https://en.wikibooks.org/wiki/Linguistics/Syntax#/media/File:Syntax_Tree_-_I_hit_the_man.svg)

12.Evolutionary Linguistics
![Evolutionary Linguisitcs](https://www.listenandlearn.org/blog/wp-content/uploads/2018/01/640px-Human_evolution.svg_.png)

Language in Animals: The question of whether animals possess language capabilities has been a subject of debate among linguists. While some argue that certain animals exhibit behaviours that resemble language, the majority of linguists do not accept this proposition. Animals, including higher primates, are known to have a system of communication involving sounds that correspond to specific meanings, which is referred to as semantics. Some parrots have been observed to develop regional "dialects" among their groups, indicating a level of variation in their vocalisations that needs to be learned. Additionally, studies on prairie dogs suggest they may communicate using simple sentences composed of nouns and adjectives. However, none of these animal communication systems demonstrate the crucial linguistic feature known as recursion, which is considered a defining characteristic of human language.
Hockett's Design Features:
Charles Hockett, a prominent linguist, proposed a set of design features that distinguish human language from animal communication systems. These features highlight the unique aspects of human language:

Reflexivity: Human language allows us to discuss and reflect on language itself. For instance, we can make statements about grammar rules, such as "Don't use a preposition at the end of a sentence!"

Displacement: Unlike animal communication, human language enables us to convey information about events, objects, or ideas that are not present in the immediate context. We can talk about things that are spatially or temporally distant from us, such as recounting an encounter with a strange person in a pub the previous day.

Arbitrariness: In human language, there is typically no inherent connection between the sounds or signs used and their meanings. For example, the word "moon" does not resemble the object it represents in any meaningful way; the relationship between the signifier and the signified is arbitrary.

Productivity: Human language exhibits an extraordinary level of productivity or creativity. Speakers can generate an infinite number of novel and meaningful utterances within their language. For instance, the sentence "The car ate the marshmallow-hating helicopter" may be unconventional, but it can still be understood by any English speaker.

Cultural transmission: Language plays a crucial role in the transmission of culture from one generation to the next. Unlike animal communication, which relies on innate biological patterns, human culture is acquired through language. Children learn the language and associated cultural knowledge from their parents and the surrounding community.

Duality: Human language has a dual nature, comprising two distinct levels—sounds and meaning. Sounds are limited and specific to each language, but meanings can be manipulated and varied. This duality allows for the creation of different words and expressions. For example, in English, the words "made" and "paid" share similar sounds but have distinct meanings, demonstrating the ability to play with sounds and their associated meanings.

Theories of Linguistic Origins:
Understanding the origins of human language is a complex task. Various theories have been proposed to explain the development and evolution of language. One influential perspective, put forth by linguist Steven Pinker in his book "The Language Instinct," likens human language to an intricate system akin to an elephant's trunk. According to Pinker, although the intermediate stages of language evolution may not be fully known, investigating these stages can provide insights into the origins of human language.

15.Sign Language - Language without Sound

![Sign Language](https://bpb-us-e1.wpmucdn.com/sites.dartmouth.edu/dist/0/2024/files/2021/04/ML.jpg)

Gestures, such as iconics, deictics, and beats, are non-linguistic movements that accompany speech but do not form complete language systems. They serve different purposes, like reflecting speech, pointing, or emphasizing certain words. However, gestures lack the complexity and variety of ideas expressed in languages like English or French, and they do not possess the unique design features of language.

Sign languages are distinct from gestures in several ways:

**Structure**: Sign languages have a grammatical structure similar to spoken languages. They consist of a combination of handshapes, facial expressions, body movements, and spatial relationships to convey meaning. Sign languages have their own syntax, morphology, and phonology, which allow for complex and nuanced communication.

**Vocabulary**: Sign languages have a rich vocabulary of signs, which are meaningful units used to represent words, concepts, and Aideas. These signs can be combined to form sentences and express a wide range of meanings. Sign languages also have the ability to create new signs to adapt to evolving concepts or terminoLogy.

**Community**: Sign languages are used by Deaf communities as their primary means of communication. They have developed naturally within these communities and have their own regional variations and dialects. Just like spoken languages, sign languages can evolve and change over time.

**Accessibility**: Sign languages provide a means of communication for individuals who are deaf or hard of hearing. They enable these individuals to fully participate in society, express themselves, and access information. Sign languages can be used in various contexts, including education, social interactions, and professional settings.

**Cultural Identity**: Sign languages are an integral part of Deaf culture. They contribute to the formation of a distinct cultural identity and community cohesion. Deaf individuals may identify themselves as users of a specific sign language, such as American Sign Language (ASL), British Sign Language (BSL), or Auslan (Australian Sign Language).

It is important to note that there can be some overlap between gestures and sign languages. For example, iconic gestures, which visually represent the meaning of a word or phrase, can be incorporated into sign languages. However, the overall structure and complexity of sign languages distinguish them as complete linguistic systems capable of expressing a wide range of ideas and concepts.

Sign languages are independent languages with their own unique lexicon, syntax, and morphology. They are not manual representations of spoken languages like English. Sign languages originated and developed naturally within Deaf communities. While some words from spoken languages may be borrowed into sign languages, this is similar to how words are borrowed between distinct natural languages.

On the other hand, manually-coded languages, such as Signed English, are manual representations of spoken languages. They are used as a means of communication between deaf and hearing individuals. Manually-coded languages are easier for hearing individuals to learn, as they follow the structure and grammar of spoken languages, but they are not true sign languages.

In summary, sign languages are complete and independent languages, while manually-coded languages are systems that represent spoken languages manually for communication purposes.
